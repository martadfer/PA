{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero\n",
    "---\n",
    ">V de Cramer - Todo o conjunto\n",
    "\n",
    ">Q de Yule - Pares\n",
    "\n",
    "Idade\n",
    "---\n",
    ">Kruskal Gamma - Todo o conjunto\n",
    "\n",
    "\n",
    ">Kruskal Gamma - Pares\n",
    "\n",
    "IMC\n",
    "---\n",
    ">Kruskal Gamma - Todo o conjunto\n",
    "\n",
    ">Kruskal Gamma - Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, norm, normaltest\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "#from scipy.spatial.distance import yule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de diretórios e Disco de leitura dos arquivos (Desktop ou Notebook) \n",
    "config_dirs = open(\"prefixo_dados.txt\").readlines() \n",
    "DIR_PREFIXO = Path(config_dirs[0].strip())\n",
    "\n",
    "DIRETORIO_PRINCIPAL =  DIR_PREFIXO / \"Projeto_PA\" / \"Projeto_PA_validado\"\n",
    "\n",
    "DIR_BASE = DIRETORIO_PRINCIPAL / \"analise_abordagens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de medidas de associações: Q de Yule, V Cramer e Kruskal Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(n,k):\n",
    "    return int(math.factorial(n) / (math.factorial(k)*math.factorial(n - k)))\n",
    "\n",
    "def yule(m):\n",
    "    m = np.array(m)\n",
    "    a = ((m[0][0]*m[1][1]) - (m[0][1]*m[1][0]))\n",
    "    b = ((m[0][0]*m[1][1]) + (m[0][1]*m[1][0]))\n",
    "    if b == 0:\n",
    "        #y = 0.0\n",
    "        return np.nan, 'Não há dados para o cálculo da diferença estatística'\n",
    "    else:\n",
    "        y = np.round(a / b, 4)\n",
    "    \n",
    "    if y < 0:\n",
    "        qual = 'Associação Inversa'\n",
    "    else:\n",
    "        qual = 'Associação Direta'\n",
    "\n",
    "    if abs(y) <= 0.2:\n",
    "         qual += ' - Diferença Estatística Ausente'\n",
    "    elif abs(y) > 0.2 and y <= 0.5:\n",
    "         qual += ' - Diferença Estatística Pequena'\n",
    "    elif abs(y) > 0.5 and y <= 0.8:\n",
    "         qual += ' - Diferença Estatística Moderada'\n",
    "    elif abs(y) > 0.8:\n",
    "        qual += ' - Diferença Estatística Grande'\n",
    "    \n",
    "    return y, qual\n",
    "\n",
    "#Referência: ausente: [0-0,2]; pequena: (0,2-0,5]; moderada: (0,5-0,8]; grande: > 0,8.\",\"\\n\",\n",
    "def cramer_v(m):\n",
    "    if min(m.shape) < 2:\n",
    "        print('\\n\\nDados com dimensão menor que 2!\\n\\n')\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        chi2, p, dof, ex = chi2_contingency(m)\n",
    "    except:\n",
    "        #chi2 = 0\n",
    "        return np.nan, 'Não há dados para o cálculo da diferença estatística'\n",
    "        \n",
    "    v = (chi2/(m.sum().sum() * (min(m.shape) - 1))) ** (0.5)\n",
    "    \n",
    "    if v <= 0.2:\n",
    "        return v, 'Diferença Estatística Ausente'\n",
    "    elif v <= 0.5:\n",
    "        return v, 'Diferença Estatística Pequena'\n",
    "    elif v <= 0.8:\n",
    "        return v, 'Diferença Estatística Moderada'\n",
    "    elif v > 0.8:\n",
    "        return v, 'Diferença Estatística Grande'\n",
    "    \n",
    "def kruskal_g(data):#, ordinal1, ordinal2, orderLabels1, orderLabels2=None):\n",
    "# myCrosstable = pd.crosstab(data[ordinal1], data[ordinal2])\n",
    "# \n",
    "# myCrosstable = myCrosstable.reindex(orderLabels1)\n",
    "#         \n",
    "# if orderLabels2 == None:\n",
    "#     myCrosstable = myCrosstable[orderLabels1]\n",
    "# else:\n",
    "#     myCrosstable = myCrosstable[orderLabels2]\n",
    "    myCrosstable = data\n",
    "    nRows = myCrosstable.shape[0]\n",
    "    nCols = myCrosstable.shape[1]\n",
    "    \n",
    "    \n",
    "    C = [[0 for x in range(nCols)] for y in range(nRows)] \n",
    "\n",
    "    # top left part\n",
    "    for i in range(nRows):\n",
    "        for j in range(nCols):\n",
    "            h = i-1\n",
    "            k = j-1        \n",
    "            if h>=0 and k>=0:            \n",
    "                for p in range(h+1):\n",
    "                    for q in range(k+1):\n",
    "                        C[i][j] = C[i][j] + list(myCrosstable.iloc[p])[q]\n",
    "\n",
    "    # bottom right part                    \n",
    "    for i in range(nRows):\n",
    "        for j in range(nCols):\n",
    "            h = i+1\n",
    "            k = j+1        \n",
    "            if h<nRows and k<nCols:            \n",
    "                for p in range(h, nRows):\n",
    "                    for q in range(k, nCols):\n",
    "                        C[i][j] = C[i][j] + list(myCrosstable.iloc[p])[q]\n",
    "                        \n",
    "    D = [[0 for x in range(nCols)] for y in range(nRows)] \n",
    "\n",
    "    # bottom left part\n",
    "    for i in range(nRows):\n",
    "        for j in range(nCols):\n",
    "            h = i+1\n",
    "            k = j-1        \n",
    "            if h<nRows and k>=0:            \n",
    "                for p in range(h, nRows):\n",
    "                    for q in range(k+1):\n",
    "                        D[i][j] = D[i][j] + list(myCrosstable.iloc[p])[q]\n",
    "\n",
    "    # top right part                    \n",
    "    for i in range(nRows):\n",
    "        for j in range(nCols):\n",
    "            h = i-1\n",
    "            k = j+1        \n",
    "            if h>=0 and k<nCols:            \n",
    "                for p in range(h+1):\n",
    "                    for q in range(k, nCols):\n",
    "                        D[i][j] = D[i][j] + list(myCrosstable.iloc[p])[q]\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    for i in range(nRows):\n",
    "        for j in range(nCols):\n",
    "            P = P + C[i][j] * list(myCrosstable.iloc[i])[j]\n",
    "            Q = Q + D[i][j] * list(myCrosstable.iloc[i])[j]\n",
    "               \n",
    "    try:\n",
    "        GKgamma = (P - Q) / (P + Q)\n",
    "    except:\n",
    "        return (np.nan, 'Não há dados para o cálculo da diferença estatística'), 0\n",
    "#    if abs(GKgamma) < .10:\n",
    "#        qual = 'Negligible'\n",
    "#    elif abs(GKgamma) < .20:\n",
    "#        qual = 'Weak'\n",
    "#    elif abs(GKgamma) < .40:\n",
    "#        qual = 'Moderate'\n",
    "#    elif abs(GKgamma) < .60:\n",
    "#        qual = 'Relatively strong'\n",
    "#    elif abs(GKgamma) < .80:\n",
    "#        qual = 'Strong'        \n",
    "#    else:\n",
    "#        qual = 'Very strong'\n",
    "\n",
    "    if GKgamma < 0:\n",
    "        qual = 'Associação Inversa'\n",
    "    else:\n",
    "        qual = 'Associação Direta'\n",
    "        \n",
    "    if abs(GKgamma) <= .20:\n",
    "        qual += ' - Diferença Estatística Ausente'\n",
    "    elif abs(GKgamma) <= .50:\n",
    "        qual += ' - Diferença Estatística Pequena'\n",
    "    elif abs(GKgamma) <= .80:\n",
    "        qual += ' - Diferença Estatística Moderada'\n",
    "    elif abs(GKgamma) > .80:\n",
    "        qual += ' - Diferença Estatística Grande'        \n",
    "\n",
    "    n = myCrosstable.sum().sum()\n",
    "    \n",
    "#    try:\n",
    "#        Z1 = GKgamma * ((P + Q) / (n * (1 - GKgamma**2)))**0.5\n",
    "#        forASE0 = 0\n",
    "#        forASE1 = 0\n",
    "#        for i in range(nRows):\n",
    "#            for j in range(nCols):\n",
    "#                forASE0 = forASE0 + list(myCrosstable.iloc[i])[j] * (Q * C[i][j] - P * D[i][j])**2\n",
    "#                forASE1 = forASE1 + list(myCrosstable.iloc[i])[j] * (C[i][j] - D[i][j])**2 \n",
    "#        ASE0 = 4 * (forASE0)**0.5 / (P + Q)**2\n",
    "#        ASE1 = 2 * (forASE1 - (P - Q)**2 / n)**0.5 / (P + Q)        \n",
    "#        Z2 = GKgamma / ASE0\n",
    "#        Z3 = GKgamma / ASE1\n",
    "#        \n",
    "#        p1 = norm.sf(Z1)\n",
    "#        p2 = norm.sf(Z2)\n",
    "#        p3 = norm.sf(Z3)\n",
    "#        \n",
    "#        zvalues = [Z1] + [Z2] + [Z3]\n",
    "#        pvalues = [p1] + [p2] + [p3]\n",
    "#    except:\n",
    "#        pvalues = [0.0,0.0,0.0]\n",
    "    return (GKgamma,qual), 0 #zvalues, pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplica a funções Teste Exato de Fisher para cálculo do p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Calcula o p_value na tabela de contigência (clusters) 2x2\n",
    "\n",
    "\n",
    "#stats.fisher_exact()\n",
    "\n",
    "#df_abordagem = pd.read_csv(lista_caminhos[3], sep=\";\", encoding='latin1')\n",
    "#df_abordagem.index = df_abordagem['Cluster'].values\n",
    "#df_abordagem = df_abordagem.drop(['Cluster'], axis = 1)\n",
    "#df_doencas = df_abordagem.loc[['Sistolica Isolada','Diastolica Isolada','Dipping','Non Dipping','Extreme Dipping','Reverse Dipping','Morning Surge','Masked','Whitecoat'], :]\n",
    "#        \n",
    "##df_genero = df_abordagem.loc[['Masculino','Feminino'], :]\n",
    "##saida_genero = analisa_genero(df_genero)\n",
    "##df_genero\n",
    "#df_doencas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A hipótese H0 é da ocorrer Diastólica Isolada no Cluter 1 E Sistólica Isolada no Cluster 2\n",
    "# A hipótese H1 é de ocorrer Diastólica Isolada no Cluster 2 E Sisólica Isolada no Cluster 1\n",
    "# Casos positivos: Ser do cluster 1 e ter a doença 1, ser do cluster 2 e ter a doença 2\n",
    "# Casos negativos: Ser do cluster 1 e ter a doença 2, ser do cluster 2 e ter a doença 1\n",
    "# Odds ratio é a probabilidade de ocorrência de casos positivos em ralação ao negativos\n",
    "# Odds ratio = 0.4\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_doencas.iloc[[1,0],[0,1]]\n",
    "#p_value = np.round(stats.fisher_exact(df)[1])\n",
    "#p_value\n",
    "#stats.fisher_exact(df,alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplica as funções para cálculo das medidas de associação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_cramer(df, df_saida):\n",
    "    n_linhas = comb(df.shape[1],2) + 1\n",
    "    n_colunas = df.shape[1]\n",
    "    \n",
    "    lista_cramer_quant = list()\n",
    "    lista_cramer_quali = list()\n",
    "    \n",
    "    resultado = cramer_v(df)\n",
    "    \n",
    "    lista_cramer_quant.append (np.round(resultado[0],4))\n",
    "    lista_cramer_quali.append (resultado[1])\n",
    "    \n",
    "    for i in range(n_linhas - 1):\n",
    "        lista_cramer_quant.append(np.nan)\n",
    "        lista_cramer_quali.append(np.nan)\n",
    "    \n",
    "    df_saida['V de Cramer (Quant)'] = lista_cramer_quant\n",
    "    df_saida['V de Cramer - Quali'] = lista_cramer_quali\n",
    "    \n",
    "    return df_saida\n",
    "\n",
    "def aplica_yule(df, df_saida):\n",
    "    #n_linhas = comb(df.shape[1],2) + 1\n",
    "    n_colunas = df.shape[1]\n",
    "    \n",
    "    lista_yule_quant = list()\n",
    "    lista_yule_quali = list()\n",
    "\n",
    "    lista_yule_quant.append(np.nan)\n",
    "    lista_yule_quali.append(np.nan)\n",
    "\n",
    "    for cluster1 in range(1, n_colunas + 1):\n",
    "        for cluster2 in range(cluster1 + 1, n_colunas + 1):\n",
    "\n",
    "            resultado = yule(df[[f'cluster {cluster1}', f'cluster {cluster2}']])\n",
    "\n",
    "            lista_yule_quant.append(np.round(resultado[0],4))\n",
    "            lista_yule_quali.append(resultado[1])\n",
    "\n",
    "    df_saida['Q de Yule - Quantitativo'] = lista_yule_quant\n",
    "    df_saida['Q de Yule - Qualitativo'] = lista_yule_quali\n",
    "    \n",
    "    return df_saida\n",
    "\n",
    "def aplica_kruskal(df, df_saida):\n",
    "    #n_linhas = comb(df.shape[1],2) + 1\n",
    "    n_colunas = df.shape[1]\n",
    "    \n",
    "    lista_kruskal_quant = list()\n",
    "    lista_kruskal_quali = list()\n",
    "\n",
    "    resultado = kruskal_g(df)[0]\n",
    "\n",
    "    lista_kruskal_quant.append(np.round(resultado[0],4))\n",
    "    lista_kruskal_quali.append(resultado[1])\n",
    "\n",
    "    for cluster1 in range(1, n_colunas + 1):\n",
    "        for cluster2 in range(cluster1 + 1, n_colunas + 1):\n",
    "            resultado = kruskal_g(df[[f'cluster {cluster1}', f'cluster {cluster2}']])[0]\n",
    "            lista_kruskal_quant.append(np.round(resultado[0],4))\n",
    "            lista_kruskal_quali.append(resultado[1])\n",
    "\n",
    "    df_saida['Gamma de Kruskal - Quantitativo'] = lista_kruskal_quant\n",
    "    df_saida['Gamma de Kruskal - Qualitativo'] = lista_kruskal_quali\n",
    "    \n",
    "    return df_saida\n",
    "\n",
    "def analisa_genero(df):\n",
    "    n_colunas = df.shape[1]\n",
    "    \n",
    "    df_saida = pd.DataFrame()\n",
    "\n",
    "    lista = ['Todos os Clusters']\n",
    "    for cluster1 in range(1, n_colunas + 1):\n",
    "        for cluster2 in range(cluster1 + 1, n_colunas + 1):\n",
    "            lista.append(f'Cluster {cluster1} e {cluster2}')\n",
    "    df_saida['SEXO'] = lista\n",
    "    \n",
    "    df_saida = aplica_cramer(df, df_saida)\n",
    "    \n",
    "    df_saida = aplica_yule(df, df_saida)\n",
    "    \n",
    "    df_saida = aplica_kruskal(df, df_saida)\n",
    "    \n",
    "    return df_saida\n",
    "\n",
    "def analisa_idade(df):\n",
    "    n_colunas = df.shape[1]\n",
    "    \n",
    "    df_saida = pd.DataFrame()\n",
    "\n",
    "    lista = ['Todos os Clusters']\n",
    "    for cluster1 in range(1, n_colunas + 1):\n",
    "        for cluster2 in range(cluster1 + 1, n_colunas + 1):\n",
    "            lista.append(f'Cluster {cluster1} e {cluster2}')\n",
    "    \n",
    "    df_saida['IDADE'] = lista\n",
    "    \n",
    "    df_saida = aplica_kruskal(df, df_saida)\n",
    "    \n",
    "    return df_saida\n",
    "\n",
    "\n",
    "def analisa_imc(df):\n",
    "    n_colunas = df.shape[1]\n",
    "    \n",
    "    df_saida = pd.DataFrame()\n",
    "\n",
    "    lista = ['Todos os Clusters']\n",
    "    for cluster1 in range(1, n_colunas + 1):\n",
    "        for cluster2 in range(cluster1 + 1, n_colunas + 1):\n",
    "            lista.append(f'Cluster {cluster1} e {cluster2}')\n",
    "    \n",
    "    df_saida['IMC'] = lista\n",
    "    \n",
    "    df_saida = aplica_kruskal(df, df_saida)\n",
    "    \n",
    "    return df_saida\n",
    "\n",
    "def analisa_doencas(df):\n",
    "    n_colunas = df.shape[1]\n",
    "    \n",
    "    df_saida = pd.DataFrame()\n",
    "\n",
    "    lista = ['Todos os Clusters']\n",
    "    for cluster1 in range(1, n_colunas + 1):\n",
    "        for cluster2 in range(cluster1 + 1, n_colunas + 1):\n",
    "            lista.append(f'Cluster {cluster1} e {cluster2}')\n",
    "    \n",
    "    df_saida['PADRÕES'] = lista\n",
    "    \n",
    "    df_saida = aplica_cramer(df, df_saida)\n",
    "    \n",
    "    return df_saida\n",
    "\n",
    "def analisa_doenca_pares(df):\n",
    "    lista_analise = list()\n",
    "    \n",
    "    doencas = list(df.index)\n",
    "    \n",
    "    for doenca1 in range(len(doencas)):\n",
    "        for doenca2 in range(doenca1 + 1, len(doencas)):\n",
    "            df_aux = df.loc[[doencas[doenca1], doencas[doenca2]], :]\n",
    "            \n",
    "            n_colunas = df_aux.shape[1]\n",
    "    \n",
    "            df_saida = pd.DataFrame()\n",
    "\n",
    "            lista = ['Todos os Clusters']\n",
    "            for cluster1 in range(1, n_colunas + 1):\n",
    "                for cluster2 in range(cluster1 + 1, n_colunas + 1):\n",
    "                    lista.append(f'Cluster {cluster1} e {cluster2}')\n",
    "\n",
    "            df_saida[doencas[doenca1] + '/' + doencas[doenca2]] = lista\n",
    "    \n",
    "            df_saida = aplica_cramer(df_aux, df_saida)\n",
    "            df_saida = aplica_yule(df_aux, df_saida)\n",
    "            \n",
    "            lista_analise.append(df_saida)\n",
    "        \n",
    "    return lista_analise\n",
    "            \n",
    "def salva_doenca_pares(df, lista):\n",
    "    doencas = list(df.index)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for doenca1 in range(len(doencas)):\n",
    "        for doenca2 in range(doenca1 + 1, len(doencas)):\n",
    "            nome = doencas[doenca1].replace(' ','_') + '&' +  doencas[doenca2].replace(' ','_')\n",
    "            lista[i].to_csv(DIR_BASE / f\"correlacao{lista_onde_salva[abordagem]}\" / f\"{algoritmo.upper()}{lista_onde_salva[abordagem]}_analise_doença_{nome}.csv\", \n",
    "                           sep=\";\", encoding=\"latin1\", index=False)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caminho = DIRETORIO_PRINCIPAL / DIR_KMEANS\n",
    "#caminho\n",
    "#diretorios = {'dict':DIR_DICT,'kmeans':DIR_KMEANS, 'nmf':DIR_NMF}\n",
    "\n",
    "nome_abordagem = {'cadastro':\"_qtd_approach_cadastro\", 'doenca':\"_qtd_approach_doenca\",\n",
    "                  'medidas':\"_qtd_approach_medidas\",'medidas_importantes':\"_qtd_approach_medidas_importantes\",\n",
    "                  'medidas_masc':\"_qtd_approach_medidas_masc\",\n",
    "                  'medidas_fem':\"_qtd_approach_medidas_fem\",'estatistica':\"_qtd_approach_estatistica\",\n",
    "                 'escolho_doenca':\"_qtd_approach_escolho_doenca\", 'categorias':\"_qtd_approach_categorias\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informe a análise kmeans\n"
     ]
    }
   ],
   "source": [
    "#DIR_DICT / f\"Dict_approach_doenca\n",
    "#_grupo_{grupo}.csv\", \n",
    "\n",
    "# Análise é uma opção do dicionário criado na célula acima\n",
    "algoritmo = input(\"Informe a análise \")\n",
    "\n",
    "#KMEANS_qtd_approach_categorias.csv\n",
    "caminho_medidas = DIR_BASE / f\"{algoritmo.upper()}{nome_abordagem['medidas']}.csv\"\n",
    "#caminho_medidas_importantes = DIR_BASE / f\"{algoritmo.upper()}{nome_abordagem['medidas_importantes']}.csv\"\n",
    "caminho_medidas_masc = DIR_BASE / f\"{algoritmo.upper()}{nome_abordagem['medidas_masc']}.csv\"\n",
    "caminho_medidas_fem = DIR_BASE / f\"{algoritmo.upper()}{nome_abordagem['medidas_fem']}.csv\"\n",
    "caminho_estatistica = DIR_BASE / f\"{algoritmo.upper()}{nome_abordagem['estatistica']}.csv\"\n",
    "caminho_doenca = DIR_BASE / f\"{algoritmo.upper( )}{nome_abordagem['doenca']}.csv\"\n",
    "caminho_cadastro = DIR_BASE / f\"{algoritmo.upper()}{nome_abordagem['cadastro']}.csv\"\n",
    "caminho_escolho_doenca = DIR_BASE / f\"{algoritmo.upper()}{nome_abordagem['escolho_doenca']}.csv\"\n",
    "caminho_categorias = DIR_BASE / f\"{algoritmo.upper()}{nome_abordagem['categorias']}.csv\"\n",
    "\n",
    "#, caminho_medidas_importantes\n",
    "\n",
    "lista_caminhos = [caminho_medidas, caminho_medidas_masc, caminho_medidas_fem, caminho_doenca, caminho_cadastro, caminho_categorias]\n",
    "\n",
    "#,'_medidas_importantes'\n",
    "\n",
    "lista_onde_salva = ['_medidas','_medidas_masc','_medidas_fem', '_doenca','_cadastro','_categorias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for abordagem in range(len(lista_caminhos)):\n",
    "    df_abordagem = pd.read_csv(lista_caminhos[abordagem], sep=\";\", encoding='latin1')\n",
    "    df_abordagem.index = df_abordagem['Cluster'].values\n",
    "    df_abordagem = df_abordagem.drop(['Cluster'], axis = 1)\n",
    "    \n",
    "    try:\n",
    "        df_genero = df_abordagem.loc[['Masculino','Feminino'], :]\n",
    "        saida_genero = analisa_genero(df_genero)\n",
    "        #  grava arquivo da abordagem por GÊNERO\n",
    "\n",
    "        saida_genero.to_csv(DIR_BASE / f\"correlacao{lista_onde_salva[abordagem]}\" / f\"{algoritmo.upper()}{lista_onde_salva[abordagem]}_analise_sexo.csv\", \n",
    "                                   sep=\";\", encoding=\"latin1\", index=False)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df_idade = df_abordagem.loc[['Jovens','Adultos','Meia-idade','Idoso','Ancião','Velhice extrema'], :]\n",
    "        saida_idade = analisa_idade(df_idade)\n",
    "\n",
    "        #  grava arquivo da abordagem por IDADE\n",
    "\n",
    "        saida_idade.to_csv(DIR_BASE /  f\"correlacao{lista_onde_salva[abordagem]}\" / f\"{algoritmo.upper()}{lista_onde_salva[abordagem]}_analise_idade.csv\", \n",
    "                                   sep=\";\", encoding=\"latin1\", index=False)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df_imc = df_abordagem.loc[['Abaixo do peso','Peso Normal','Sobrepeso','Obesidade grau 1','Obesidade grau 2','Obesidade Grau 3'], :]\n",
    "        saida_imc = analisa_imc(df_imc)\n",
    "\n",
    "        #  grava arquivo da abordagem por IMC\n",
    "\n",
    "        saida_imc.to_csv(DIR_BASE / f\"correlacao{lista_onde_salva[abordagem]}\" / f\"{algoritmo.upper()}{lista_onde_salva[abordagem]}_analise_imc.csv\", \n",
    "                                   sep=\";\", encoding=\"latin1\", index=False)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df_doencas = df_abordagem.loc[['Sistolica Isolada','Diastolica Isolada','Dipping','Non Dipping','Extreme Dipping','Reverse Dipping','Morning Surge','Masked','Whitecoat'], :]\n",
    "        \n",
    "        saida_doencas = analisa_doencas(df_doencas)\n",
    "\n",
    "        #  grava arquivo da abordagem por PADRÂO DE DOENÇA\n",
    "\n",
    "        saida_doencas.to_csv(DIR_BASE / f\"correlacao{lista_onde_salva[abordagem]}\" / f\"{algoritmo.upper()}{lista_onde_salva[abordagem]}_analise_doenca.csv\", \n",
    "                                   sep=\";\", encoding=\"latin1\", index=False)\n",
    "        \n",
    "        lista_analises = analisa_doenca_pares(df_doencas)\n",
    "        salva_doenca_pares(df_doencas, lista_analises)\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster 1</th>\n",
       "      <th>cluster 2</th>\n",
       "      <th>cluster 3</th>\n",
       "      <th>cluster 4</th>\n",
       "      <th>cluster 5</th>\n",
       "      <th>cluster 6</th>\n",
       "      <th>cluster 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Abaixo do peso</td>\n",
       "      <td>54.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Peso Normal</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sobrepeso</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>2041.0</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Obesidade grau 1</td>\n",
       "      <td>510.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Obesidade grau 2</td>\n",
       "      <td>165.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Obesidade Grau 3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cluster 1  cluster 2  cluster 3  cluster 4  cluster 5  \\\n",
       "Abaixo do peso         54.0       31.0        9.0       12.0       26.0   \n",
       "Peso Normal          1107.0      811.0      568.0     1083.0     1156.0   \n",
       "Sobrepeso            1120.0     1245.0     1079.0     2041.0     1813.0   \n",
       "Obesidade grau 1      510.0      584.0      463.0      921.0      830.0   \n",
       "Obesidade grau 2      165.0      137.0      123.0      280.0      256.0   \n",
       "Obesidade Grau 3       38.0       49.0       60.0      104.0       77.0   \n",
       "\n",
       "                  cluster 6  cluster 7  \n",
       "Abaixo do peso         19.0        6.0  \n",
       "Peso Normal           502.0      205.0  \n",
       "Sobrepeso             772.0      336.0  \n",
       "Obesidade grau 1      345.0      149.0  \n",
       "Obesidade grau 2       86.0       31.0  \n",
       "Obesidade Grau 3       26.0       13.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abordagem = pd.read_csv(lista_caminhos[0], sep=\";\", encoding='latin1')\n",
    "df_abordagem.index = df_abordagem['Cluster'].values\n",
    "df_abordagem = df_abordagem.drop(['Cluster'], axis = 1)\n",
    "df_imc = df_abordagem.loc[['Abaixo do peso','Peso Normal','Sobrepeso','Obesidade grau 1','Obesidade grau 2','Obesidade Grau 3'], :]\n",
    "#saida_imc = analisa_imc(df_imc)\n",
    "df_imc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2761605035405192, 0.3134371357583795)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "                cluster 1    cluster 2\n",
    "abaixo do peso         54           31\n",
    "peso normal          1107          811\n",
    "\n",
    "\n",
    "              Variável Y\n",
    "Variável X    Sim     Não\n",
    "Sim            a-Positivo     c-Negativo\n",
    "Não            b-Negativo     d-Positivo\n",
    "\n",
    "OR = (a / b) / (c / d) = (a * d) / (b * c)\n",
    "\n",
    "'''\n",
    "a = np.sum(df_imc.loc['Abaixo do peso':'Peso Normal','cluster 1'])\n",
    "b = np.sum(df_imc.loc['Sobrepeso':,'cluster 1'])\n",
    "c = np.sum(df_imc.loc['Abaixo do peso':'Peso Normal','cluster 2'])\n",
    "d = np.sum(df_imc.loc['Sobrepeso':,'cluster 2'])\n",
    "\n",
    "matriz = np.array([[a, c], [b, d]])\n",
    "\n",
    "import scipy.stats as stats\n",
    "stats.fisher_exact([[54,31],[1107,811]],alternative='two-sided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1161.  842.]\n",
      " [1833. 2015.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.5157679284378633, 6.230458088316589e-14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(matriz)\n",
    "'''\n",
    "alternative='two-sided' = a probabilidade de H0 ser igual a H1\n",
    "alternative='less' H1 ser menor que H0\n",
    "alternative='greater' H1 ser maior que H0\n",
    "'''\n",
    "stats.fisher_exact(matriz,alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2761605035405192"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 54\n",
    "b = 1107\n",
    "c = 31\n",
    "d = 811\n",
    "\n",
    "(a * d) / (b * c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#df_categorias = pd.read_csv(caminho_categorias, sep=\";\", encoding='latin1')\n",
    "#df_categorias.index = df_categorias['Cluster'].values\n",
    "#df_categorias = df_categorias.drop(['Cluster'], axis = 1)\n",
    "#df_categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_genero = df_categorias.loc[['Masculino','Feminino'], :]\n",
    "#df_genero\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_idade = df_categorias.loc[['Jovens','Adultos','Meia-idade','Idoso','Ancião','Velhice extrema'], :]\n",
    "#df_idade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise por DOENÇA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_doencas = df_categorias.loc[['Sistolica Isolada','Diastolica Isolada','Dipping','Non Dipping','Extreme Dipping','Reverse Dipping','Morning Surge','Masked','Whitecoat','Normotenso'], :]\n",
    "#df_doencas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise por IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_imc = df_categorias.loc[['Abaixo do peso','Peso Normal','Sobrepeso','Obesidade grau 1','Obesidade grau 2','Obesidade Grau 3'], :]\n",
    "#df_imc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise por GÊNERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saida_genero = analisa_genero(df_genero)\n",
    "\n",
    "##  grava arquivo da abordagem por GÊNERO\n",
    "\n",
    "#saida_genero.to_csv(DIR_BASE / \"correlacao_cadastro\" / f\"{algoritmo.upper()}_analise_sexo.csv\", \n",
    "#                           sep=\";\", encoding=\"latin1\", index=False)\n",
    "\n",
    "#saida_genero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise por IDADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saida_idade = analisa_idade(df_idade)\n",
    "#saida_idade\n",
    "#\n",
    "##  grava arquivo da abordagem por IDADE\n",
    "#\n",
    "#saida_genero.to_csv(DIR_BASE / \"correlacao_cadastro\" / f\"{algoritmo.upper()}_analise_idade.csv\", \n",
    "#                           sep=\";\", encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise por DOENÇA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saida_doencas = analisa_doencas(df_doencas)\n",
    "#saida_doencas\n",
    "#\n",
    "##  grava arquivo da abordagem por PADRÂO DE DOENÇA\n",
    "#\n",
    "#saida_genero.to_csv(DIR_BASE / \"correlacao_doenca\" / f\"{algoritmo.upper()}_analise_doenca.csv\", \n",
    "#                           sep=\";\", encoding=\"latin1\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise por DOENÇA - Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_analises = analisa_doenca_pares(df_doencas)\n",
    "#salva_doenca_pares(df_doencas, lista_analises)\n",
    "#lista_analises[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise por IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saida_imc = analisa_imc(df_imc)\n",
    "#saida_imc\n",
    "#\n",
    "##  grava arquivo da abordagem por IMC\n",
    "#\n",
    "#saida_genero.to_csv(DIR_BASE / \"correlacao_cadastro\" / f\"{algoritmo.upper()}_analise_imc.csv\", \n",
    "#                           sep=\";\", encoding=\"latin1\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
