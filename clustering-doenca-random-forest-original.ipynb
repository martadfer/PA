{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "config_dirs = open(\"prefixo_dados.txt\").readlines() \n",
    "DIR_PREFIXO = Path(config_dirs[0].strip())\n",
    "\n",
    "\n",
    "DIRETORIO_PRINCIPAL =  DIR_PREFIXO / \"Projeto_PA\" / \"Projeto_PA_validado\"\n",
    "DIRETORIO_DATASET = DIR_PREFIXO / \"Projeto_PA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_identificacao</th>\n",
       "      <th>data_nascimento</th>\n",
       "      <th>genero</th>\n",
       "      <th>idade</th>\n",
       "      <th>peso</th>\n",
       "      <th>altura</th>\n",
       "      <th>data_exame</th>\n",
       "      <th>sist 9:00</th>\n",
       "      <th>sist 9:15</th>\n",
       "      <th>sist 9:30</th>\n",
       "      <th>...</th>\n",
       "      <th>Mediana Sistolica em 24h</th>\n",
       "      <th>Mediana Diastolica em 24h</th>\n",
       "      <th>AUC Sistolica em 24h</th>\n",
       "      <th>AUC Diastolica em 24h</th>\n",
       "      <th>AUC PP Daytime</th>\n",
       "      <th>AUC PP Nighttime</th>\n",
       "      <th>DP Sistolica em 24h</th>\n",
       "      <th>DP Diastolica em 24h</th>\n",
       "      <th>Picos Sistolica</th>\n",
       "      <th>Picos Diastolica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1923-10-05</td>\n",
       "      <td>M</td>\n",
       "      <td>94.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>160</td>\n",
       "      <td>2018-09-10 12:25:23</td>\n",
       "      <td>105.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>9545.5</td>\n",
       "      <td>4902.0</td>\n",
       "      <td>3748.0</td>\n",
       "      <td>841.5</td>\n",
       "      <td>16.52</td>\n",
       "      <td>11.36</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1948-10-07</td>\n",
       "      <td>M</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>165</td>\n",
       "      <td>2018-12-26 07:39:41</td>\n",
       "      <td>103.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8586.5</td>\n",
       "      <td>5034.5</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>7.51</td>\n",
       "      <td>6.65</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1999-03-23</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>197</td>\n",
       "      <td>2018-12-26 08:06:19</td>\n",
       "      <td>147.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>10674.0</td>\n",
       "      <td>6154.0</td>\n",
       "      <td>3721.0</td>\n",
       "      <td>751.5</td>\n",
       "      <td>12.70</td>\n",
       "      <td>13.01</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1978-01-26</td>\n",
       "      <td>F</td>\n",
       "      <td>40.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1,64</td>\n",
       "      <td>2018-12-26 08:19:06</td>\n",
       "      <td>140.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10679.5</td>\n",
       "      <td>6420.5</td>\n",
       "      <td>3642.0</td>\n",
       "      <td>602.5</td>\n",
       "      <td>16.13</td>\n",
       "      <td>10.34</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1990-03-07</td>\n",
       "      <td>M</td>\n",
       "      <td>28.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>172</td>\n",
       "      <td>2018-12-26 08:26:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9141.5</td>\n",
       "      <td>6118.0</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>12.27</td>\n",
       "      <td>12.79</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19556</td>\n",
       "      <td>21786</td>\n",
       "      <td>1972-11-25</td>\n",
       "      <td>M</td>\n",
       "      <td>47.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>165</td>\n",
       "      <td>2020-09-10 16:03:08</td>\n",
       "      <td>163.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>12224.5</td>\n",
       "      <td>9265.0</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>474.5</td>\n",
       "      <td>18.66</td>\n",
       "      <td>14.80</td>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19557</td>\n",
       "      <td>21787</td>\n",
       "      <td>1970-10-19</td>\n",
       "      <td>M</td>\n",
       "      <td>49.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>183</td>\n",
       "      <td>2020-09-10 16:21:02</td>\n",
       "      <td>114.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10970.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>3319.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>17.22</td>\n",
       "      <td>13.67</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19558</td>\n",
       "      <td>21788</td>\n",
       "      <td>1985-03-15</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>167</td>\n",
       "      <td>2020-09-10 16:44:53</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9245.0</td>\n",
       "      <td>4935.5</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>713.5</td>\n",
       "      <td>14.36</td>\n",
       "      <td>8.29</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19559</td>\n",
       "      <td>21792</td>\n",
       "      <td>1952-04-21</td>\n",
       "      <td>F</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160</td>\n",
       "      <td>2020-09-10 17:25:50</td>\n",
       "      <td>94.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>8989.5</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>2815.5</td>\n",
       "      <td>460.0</td>\n",
       "      <td>14.14</td>\n",
       "      <td>9.38</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19560</td>\n",
       "      <td>21793</td>\n",
       "      <td>1971-01-14</td>\n",
       "      <td>M</td>\n",
       "      <td>49.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>179</td>\n",
       "      <td>2020-09-10 17:42:01</td>\n",
       "      <td>111.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>9812.0</td>\n",
       "      <td>6746.5</td>\n",
       "      <td>2400.5</td>\n",
       "      <td>612.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>12.71</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19561 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       numero_identificacao data_nascimento genero  idade   peso altura  \\\n",
       "0                         4      1923-10-05      M   94.0   85.0    160   \n",
       "1                         5      1948-10-07      M   70.0   80.0    165   \n",
       "2                         6      1999-03-23      M   19.0  100.0    197   \n",
       "3                         7      1978-01-26      F   40.0   65.0   1,64   \n",
       "4                         8      1990-03-07      M   28.0  120.0    172   \n",
       "...                     ...             ...    ...    ...    ...    ...   \n",
       "19556                 21786      1972-11-25      M   47.0   75.0    165   \n",
       "19557                 21787      1970-10-19      M   49.0   90.0    183   \n",
       "19558                 21788      1985-03-15      F   35.0   93.0    167   \n",
       "19559                 21792      1952-04-21      F   68.0   64.0    160   \n",
       "19560                 21793      1971-01-14      M   49.0   99.0    179   \n",
       "\n",
       "                data_exame  sist 9:00  sist 9:15  sist 9:30  ...  \\\n",
       "0      2018-09-10 12:25:23      105.0      108.0      116.0  ...   \n",
       "1      2018-12-26 07:39:41      103.0      114.0       82.0  ...   \n",
       "2      2018-12-26 08:06:19      147.0      148.0      156.0  ...   \n",
       "3      2018-12-26 08:19:06      140.0      139.0      142.0  ...   \n",
       "4      2018-12-26 08:26:59        NaN      110.0      101.0  ...   \n",
       "...                    ...        ...        ...        ...  ...   \n",
       "19556  2020-09-10 16:03:08      163.0      198.0      172.0  ...   \n",
       "19557  2020-09-10 16:21:02      114.0      120.0      164.0  ...   \n",
       "19558  2020-09-10 16:44:53      107.0      110.0      103.0  ...   \n",
       "19559  2020-09-10 17:25:50       94.0      107.0      112.0  ...   \n",
       "19560  2020-09-10 17:42:01      111.0      104.0      103.0  ...   \n",
       "\n",
       "       Mediana Sistolica em 24h  Mediana Diastolica em 24h  \\\n",
       "0                         118.5                       59.0   \n",
       "1                         106.0                       62.0   \n",
       "2                         133.0                       79.0   \n",
       "3                         131.0                       80.0   \n",
       "4                         115.0                       78.0   \n",
       "...                         ...                        ...   \n",
       "19556                     152.0                      116.0   \n",
       "19557                     136.0                       85.0   \n",
       "19558                     112.0                       62.0   \n",
       "19559                     109.5                       68.0   \n",
       "19560                     121.0                       86.0   \n",
       "\n",
       "       AUC Sistolica em 24h  AUC Diastolica em 24h  AUC PP Daytime  \\\n",
       "0                    9545.5                 4902.0          3748.0   \n",
       "1                    8586.5                 5034.5          2915.0   \n",
       "2                   10674.0                 6154.0          3721.0   \n",
       "3                   10679.5                 6420.5          3642.0   \n",
       "4                    9141.5                 6118.0          2405.0   \n",
       "...                     ...                    ...             ...   \n",
       "19556               12224.5                 9265.0          2439.0   \n",
       "19557               10970.0                 6819.0          3319.0   \n",
       "19558                9245.0                 4935.5          3556.0   \n",
       "19559                8989.5                 5660.0          2815.5   \n",
       "19560                9812.0                 6746.5          2400.5   \n",
       "\n",
       "       AUC PP Nighttime  DP Sistolica em 24h  DP Diastolica em 24h  \\\n",
       "0                 841.5                16.52                 11.36   \n",
       "1                 606.0                 7.51                  6.65   \n",
       "2                 751.5                12.70                 13.01   \n",
       "3                 602.5                16.13                 10.34   \n",
       "4                 566.0                12.27                 12.79   \n",
       "...                 ...                  ...                   ...   \n",
       "19556             474.5                18.66                 14.80   \n",
       "19557             738.0                17.22                 13.67   \n",
       "19558             713.5                14.36                  8.29   \n",
       "19559             460.0                14.14                  9.38   \n",
       "19560             612.0                13.92                 12.71   \n",
       "\n",
       "       Picos Sistolica  Picos Diastolica  \n",
       "0                   11                34  \n",
       "1                    9                23  \n",
       "2                   19                19  \n",
       "3                   21                 9  \n",
       "4                   10                11  \n",
       "...                ...               ...  \n",
       "19556               49                60  \n",
       "19557               32                27  \n",
       "19558               14                26  \n",
       "19559               19                13  \n",
       "19560               11                27  \n",
       "\n",
       "[19561 rows x 208 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DIRETORIO_PRINCIPAL / \"padrao_doenca\" / \"classificados_por_padroes_de_doenca_estatistica.csv\", sep=\";\")\n",
    "#df = pd.read_csv(\"../input/doenca-cardio/classificados_por_padroes_de_doenca_estatistica.csv\", delimiter=\";\")\n",
    "#display(HTML(df.to_html()))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_nascimento</th>\n",
       "      <th>genero</th>\n",
       "      <th>idade</th>\n",
       "      <th>peso</th>\n",
       "      <th>altura</th>\n",
       "      <th>data_exame</th>\n",
       "      <th>sist 9:00</th>\n",
       "      <th>sist 9:15</th>\n",
       "      <th>sist 9:30</th>\n",
       "      <th>sist 9:45</th>\n",
       "      <th>...</th>\n",
       "      <th>diast 6:45</th>\n",
       "      <th>diast 7:00</th>\n",
       "      <th>diast 7:15</th>\n",
       "      <th>diast 7:30</th>\n",
       "      <th>diast 7:45</th>\n",
       "      <th>diast 8:00</th>\n",
       "      <th>diast 8:15</th>\n",
       "      <th>diast 8:30</th>\n",
       "      <th>diast 8:45</th>\n",
       "      <th>whitecoat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1923-10-05</td>\n",
       "      <td>M</td>\n",
       "      <td>94.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>160</td>\n",
       "      <td>2018-09-10 12:25:23</td>\n",
       "      <td>105.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>[('12:39', 140.0, 80.0), ('12:48', nan, nan), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1948-10-07</td>\n",
       "      <td>M</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>165</td>\n",
       "      <td>2018-12-26 07:39:41</td>\n",
       "      <td>103.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>[('08:04', 114.0, 60.0), ('08:15', 111.0, 74.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1999-03-23</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>197</td>\n",
       "      <td>2018-12-26 08:06:19</td>\n",
       "      <td>147.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>[('08:11', 133.0, 86.0), ('08:15', 137.0, 87.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1978-01-26</td>\n",
       "      <td>F</td>\n",
       "      <td>40.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1,64</td>\n",
       "      <td>2018-12-26 08:19:06</td>\n",
       "      <td>140.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>[('08:22', 153.0, 89.0), ('08:30', 153.0, 90.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1990-03-07</td>\n",
       "      <td>M</td>\n",
       "      <td>28.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>172</td>\n",
       "      <td>2018-12-26 08:26:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>[('08:31', 106.0, 81.0), ('08:48', 116.0, 72.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19556</td>\n",
       "      <td>1972-11-25</td>\n",
       "      <td>M</td>\n",
       "      <td>47.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>165</td>\n",
       "      <td>2020-09-10 16:03:08</td>\n",
       "      <td>163.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>[('17:46', 162.0, 127.0), ('18:03', 157.0, 118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19557</td>\n",
       "      <td>1970-10-19</td>\n",
       "      <td>M</td>\n",
       "      <td>49.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>183</td>\n",
       "      <td>2020-09-10 16:21:02</td>\n",
       "      <td>114.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[('16:29', 115.0, 72.0), ('16:48', nan, nan), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19558</td>\n",
       "      <td>1985-03-15</td>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>167</td>\n",
       "      <td>2020-09-10 16:44:53</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>[('16:51', 126.0, 68.0), ('17:00', 128.0, 60.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19559</td>\n",
       "      <td>1952-04-21</td>\n",
       "      <td>F</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>160</td>\n",
       "      <td>2020-09-10 17:25:50</td>\n",
       "      <td>94.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>[('17:54', 132.0, 77.0), ('18:03', nan, nan), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19560</td>\n",
       "      <td>1971-01-14</td>\n",
       "      <td>M</td>\n",
       "      <td>49.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>179</td>\n",
       "      <td>2020-09-10 17:42:01</td>\n",
       "      <td>111.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>[('17:48', 107.0, 83.0), ('18:00', 114.0, 75.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19561 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_nascimento genero  idade   peso altura           data_exame  \\\n",
       "0          1923-10-05      M   94.0   85.0    160  2018-09-10 12:25:23   \n",
       "1          1948-10-07      M   70.0   80.0    165  2018-12-26 07:39:41   \n",
       "2          1999-03-23      M   19.0  100.0    197  2018-12-26 08:06:19   \n",
       "3          1978-01-26      F   40.0   65.0   1,64  2018-12-26 08:19:06   \n",
       "4          1990-03-07      M   28.0  120.0    172  2018-12-26 08:26:59   \n",
       "...               ...    ...    ...    ...    ...                  ...   \n",
       "19556      1972-11-25      M   47.0   75.0    165  2020-09-10 16:03:08   \n",
       "19557      1970-10-19      M   49.0   90.0    183  2020-09-10 16:21:02   \n",
       "19558      1985-03-15      F   35.0   93.0    167  2020-09-10 16:44:53   \n",
       "19559      1952-04-21      F   68.0   64.0    160  2020-09-10 17:25:50   \n",
       "19560      1971-01-14      M   49.0   99.0    179  2020-09-10 17:42:01   \n",
       "\n",
       "       sist 9:00  sist 9:15  sist 9:30  sist 9:45  ...  diast 6:45  \\\n",
       "0          105.0      108.0      116.0      104.0  ...         NaN   \n",
       "1          103.0      114.0       82.0      104.0  ...         NaN   \n",
       "2          147.0      148.0      156.0      140.0  ...        86.0   \n",
       "3          140.0      139.0      142.0      137.0  ...        56.0   \n",
       "4            NaN      110.0      101.0      108.0  ...         NaN   \n",
       "...          ...        ...        ...        ...  ...         ...   \n",
       "19556      163.0      198.0      172.0      148.0  ...       114.0   \n",
       "19557      114.0      120.0      164.0      116.0  ...        73.0   \n",
       "19558      107.0      110.0      103.0        NaN  ...        50.0   \n",
       "19559       94.0      107.0      112.0      124.0  ...         NaN   \n",
       "19560      111.0      104.0      103.0      101.0  ...         NaN   \n",
       "\n",
       "       diast 7:00  diast 7:15  diast 7:30  diast 7:45  diast 8:00  diast 8:15  \\\n",
       "0             NaN         NaN         NaN        67.0        61.0        69.0   \n",
       "1            74.0         NaN         NaN         NaN        60.0        74.0   \n",
       "2            93.0         NaN         NaN         NaN        86.0        87.0   \n",
       "3            62.0        83.0       104.0         NaN         NaN        89.0   \n",
       "4             NaN        93.0        68.0        91.0         NaN         NaN   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "19556       126.0         NaN         NaN         NaN       123.0       121.0   \n",
       "19557        59.0        74.0        68.0        86.0        96.0       107.0   \n",
       "19558        50.0        53.0        52.0        62.0        68.0        61.0   \n",
       "19559        64.0        76.0        72.0        69.0        75.0        74.0   \n",
       "19560         NaN        71.0        73.0        56.0        57.0        65.0   \n",
       "\n",
       "       diast 8:30  diast 8:45  \\\n",
       "0            62.0        51.0   \n",
       "1            70.0        67.0   \n",
       "2            82.0        82.0   \n",
       "3            90.0        72.0   \n",
       "4            81.0        72.0   \n",
       "...           ...         ...   \n",
       "19556       119.0       123.0   \n",
       "19557       106.0        93.0   \n",
       "19558        64.0        60.0   \n",
       "19559        69.0        67.0   \n",
       "19560        68.0        82.0   \n",
       "\n",
       "                                               whitecoat  \n",
       "0      [('12:39', 140.0, 80.0), ('12:48', nan, nan), ...  \n",
       "1      [('08:04', 114.0, 60.0), ('08:15', 111.0, 74.0...  \n",
       "2      [('08:11', 133.0, 86.0), ('08:15', 137.0, 87.0...  \n",
       "3      [('08:22', 153.0, 89.0), ('08:30', 153.0, 90.0...  \n",
       "4      [('08:31', 106.0, 81.0), ('08:48', 116.0, 72.0...  \n",
       "...                                                  ...  \n",
       "19556  [('17:46', 162.0, 127.0), ('18:03', 157.0, 118...  \n",
       "19557  [('16:29', 115.0, 72.0), ('16:48', nan, nan), ...  \n",
       "19558  [('16:51', 126.0, 68.0), ('17:00', 128.0, 60.0...  \n",
       "19559  [('17:54', 132.0, 77.0), ('18:03', nan, nan), ...  \n",
       "19560  [('17:48', 107.0, 83.0), ('18:00', 114.0, 75.0...  \n",
       "\n",
       "[19561 rows x 171 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all averages, standard deviations, and classes (types of diseases)\n",
    "new_df = df.iloc[:,1:172]\n",
    "#display(HTML(new_df.to_html()))\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dff = new_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data_nascimento', 'genero', 'idade', 'peso', 'altura', 'data_exame',\n",
      "       'sist 9:00', 'sist 9:15', 'sist 9:30', 'sist 9:45',\n",
      "       ...\n",
      "       'diast 6:45', 'diast 7:00', 'diast 7:15', 'diast 7:30', 'diast 7:45',\n",
      "       'diast 8:00', 'diast 8:15', 'diast 8:30', 'diast 8:45', 'whitecoat'],\n",
      "      dtype='object', length=171)\n"
     ]
    }
   ],
   "source": [
    "print(new_dff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Gender M and F to binary \n",
    "# cleanup_nums = {\"Morning Surge\": {\"NaN\": False}}\n",
    "\n",
    "# new_dff.replace(cleanup_nums, inplace=True)\n",
    "#display(HTML(new_dff.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '1923-10-05'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-baf34001dd00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnew_dff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleanup_nums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnew_dff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_dff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   5880\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5881\u001b[0m             new_data = self._data.astype(\n\u001b[1;32m-> 5882\u001b[1;33m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5883\u001b[0m             )\n\u001b[0;32m   5884\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m                     \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m                     \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m                     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[1;31m# TODO(extension)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '1923-10-05'"
     ]
    }
   ],
   "source": [
    "# transform Gender M and F to binary \n",
    "cleanup_nums = {\"genero\": {\"M\": True, \"F\": False}}\n",
    "\n",
    "new_dff.replace(cleanup_nums, inplace=True)\n",
    "new_dff = new_dff.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(HTML(new_dff.to_html()))\n",
    "new_dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = new_dff.iloc[:,:161]\n",
    "#display(HTML(df_X.to_html()))\n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y = new_dff.iloc[:,161:]\n",
    "#display(HTML(df_Y.to_html()))\n",
    "df_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split between train and test with test_size of 0.3 (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape[0])\n",
    "display(X_train.head())\n",
    "\n",
    "print(X_test.shape[0])\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df_Y.values, axis=0).shape[0])\n",
    "display(np.unique(df_Y.values, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(np.argmax(df_Y.values, axis=1)))\n",
    "listm = np.unique(df_Y.values, axis=0).tolist()\n",
    "print(listm)\n",
    "print(listm[0])\n",
    "\n",
    "print([''.join(str(e) for e in i) for i in listm])\n",
    "\n",
    "print([int(''.join(str(e) for e in i),2) for i in listm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique([int(''.join(str(e) for e in i),2) for i in df_Y.values.tolist()], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from sklearn.externals.six import StringIO  \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Ms = np.arange(2,10)\n",
    "mean_acc = list()\n",
    "\n",
    "for k in Ms:\n",
    "    \n",
    "    #create classifier\n",
    "    drugTree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth=k)\n",
    "    \n",
    "    #create pipeline with scaler and classifier\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', drugTree)])\n",
    "    \n",
    "    # perform cv=10 with F1_scored weighted\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv = 5, scoring='f1_weighted')\n",
    "    mean_acc.append(np.mean(scores))\n",
    "\n",
    "# mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Ms,mean_acc,'g')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('max depth')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"The best accuracy was with\", max(mean_acc), \"with max_depth=\", Ms[np.argmax(mean_acc)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_drugTree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth = Ms[np.argmax(mean_acc)] )\n",
    "best_drugTree.fit(X_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTree = best_drugTree.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Accuracy: ', accuracy_score(y_train, predTree))\n",
    "print('Train F1_score: ', f1_score(y_train, predTree, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_scaled= scaler.transform(X_test)\n",
    "# test_X_scaled[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predTree  = best_drugTree.predict(test_X_scaled)\n",
    "#print(test_predTree)\n",
    "\n",
    "print('Test Accuracy: ', accuracy_score(y_test, test_predTree))\n",
    "\n",
    "# print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "print('Test F1_score: ', f1_score(y_test, test_predTree, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-output classifier - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth = Ms[np.argmax(mean_acc)] )\n",
    "#clf = MultiOutputClassifier(best_tree).fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predTree_m  = clf.predict(test_X_scaled)\n",
    "#print(test_predTree)\n",
    "\n",
    "# print('Test Accuracy: ', accuracy_score(y_test, test_predTree_m))\n",
    "\n",
    "# # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "# print('Test F1_score: ', f1_score(y_test, test_predTree_m, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-output classifier - RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ms = np.arange(2,20)\n",
    "# mean_acc = list()\n",
    "\n",
    "# for k in Ms:\n",
    "    \n",
    "#     #create classifier\n",
    "#     clf_forest = RandomForestClassifier(criterion=\"entropy\", random_state=123, max_depth=k)\n",
    "    \n",
    "#     #create pipeline with scaler and classifier\n",
    "#     pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', clf_forest)])\n",
    "    \n",
    "#     # perform cv=10 with F1_scored weighted\n",
    "#     scores = cross_val_score(pipeline, X_train, y_train, cv = 5, scoring='f1_weighted')\n",
    "#     mean_acc.append(np.mean(scores))\n",
    "\n",
    "# mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(Ms,mean_acc,'g')\n",
    "# plt.ylabel('F1 score')\n",
    "# plt.xlabel('Max leaf nodes')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The best accuracy was with\", max(mean_acc), \"with max_depth=\", Ms[np.argmax(mean_acc)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_forest = RandomForestClassifier(criterion=\"entropy\", random_state=123, max_depth = Ms[np.argmax(mean_acc)] )\n",
    "# best_forest.fit(X_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_m  = best_forest.predict(test_X_scaled)\n",
    "# print(test_predTree)\n",
    "\n",
    "# print('Test Accuracy: ', accuracy_score(y_test, test_pred_m))\n",
    "\n",
    "# # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "# print('Test F1_score: ', f1_score(y_test, test_pred_m, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier per each class - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = y_train.shape[1]\n",
    "classes = y_train.columns.values.tolist()\n",
    "print(classes)\n",
    "print(n_classes)\n",
    "print(y_train.iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print('disease:'+str(classes[i]))\n",
    "    y = y_train.iloc[:,i].values\n",
    "    print('ones: ',(y == 1).sum())\n",
    "    print('zeros:',(y == 0).sum())\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print('disease:'+str(classes[i]))\n",
    "    y = y_test.iloc[:,i].values\n",
    "    print('ones: ',(y == 1).sum())\n",
    "    print('zeros:',(y == 0).sum())\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_estimators = list()\n",
    "Ms = np.arange(2,100)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_acc = list()\n",
    "    y = y_train.iloc[:,i].values\n",
    "    for k in Ms:\n",
    "\n",
    "        #create classifier\n",
    "        tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth=k)\n",
    "\n",
    "        #create pipeline with scaler and classifier\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', tree)])\n",
    "\n",
    "        # perform cv=10 with F1_scored weighted\n",
    "        scores = cross_val_score(pipeline, X_train, y, cv = 5, scoring='f1_weighted')\n",
    "        mean_acc.append(np.mean(scores))\n",
    "    mean_acc_estimators.append(mean_acc)\n",
    "# mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(len(mean_acc_estimators)):\n",
    "    plt.plot(Ms, mean_acc_estimators[i], label=classes[i])   \n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Max depth')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print( \"The best accuracy was with: \"+str(i), max(mean_acc_estimators[i]), \"with max_depth=\", Ms[np.argmax(mean_acc_estimators[i])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = list()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    best_Tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth = Ms[np.argmax(mean_acc_estimators[i])] )\n",
    "    y = y_train.iloc[:,i].values\n",
    "    best_Tree.fit(X_scaled,y)\n",
    "    estimators.append(best_Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "\n",
    "    test_pred_m  = estimators[i].predict(test_X_scaled)\n",
    "    print('Test Accuracy: '+str(classes[i])+' -- ', accuracy_score(y_test.iloc[:,i], test_pred_m))\n",
    "\n",
    "    # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "    print('Test F1_score: '+str(classes[i])+' -- ', f1_score(y_test.iloc[:,i], test_pred_m, average='weighted'))\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier per each class - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_estimators_LR = list()\n",
    "Cks = np.linspace(1e-3,100, 50)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_acc = list()\n",
    "    y = y_train.iloc[:,i].values\n",
    "\n",
    "    for Ck in Cks:\n",
    "\n",
    "        #create pipeline with scaler and classifier\n",
    "        LR = LogisticRegression(C=Ck, solver='liblinear')\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', LR)])\n",
    "\n",
    "        # perform cv using F1_score weighted\n",
    "        scores = cross_val_score(pipeline, X_train, y, cv = 5, scoring='f1_weighted')\n",
    "        mean_acc.append(np.mean(scores))\n",
    "    mean_acc_estimators_LR.append(mean_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mean_acc_estimators_LR))\n",
    "print(Cks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(len(mean_acc_estimators_LR)):\n",
    "    plt.plot(Cks, mean_acc_estimators_LR[i], label=classes[i])    \n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Regularization parameter (C)')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print( \"The best accuracy was with: \"+str(classes[i]), max(mean_acc_estimators_LR[i]), \"with C=\", Cks[np.argmax(mean_acc_estimators_LR[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators_LR = list()\n",
    "\n",
    "# for i in range(n_classes):\n",
    "#     best_LR = LogisticRegression(C=Cks[np.argmax(mean_acc_estimators_LR[i])], solver='liblinear')\n",
    "#     y = y_train.iloc[:,i].values\n",
    "#     best_LR.fit(X_scaled,y)\n",
    "#     estimators_LR.append(best_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(n_classes):\n",
    "\n",
    "#     test_pred_m  = estimators_LR[i].predict(test_X_scaled)\n",
    "#     print('Test Accuracy: '+str(classes[i])+' -- ', accuracy_score(y_test.iloc[:,i], test_pred_m))\n",
    "\n",
    "#     # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "#     print('Test F1_score: '+str(classes[i])+' -- ', f1_score(y_test.iloc[:,i], test_pred_m, average='weighted'))\n",
    "#     print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier per each class - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_estimators_RF = list()\n",
    "Ns = np.arange(2,50)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_acc = list()\n",
    "    y = y_train.iloc[:,i].values\n",
    "\n",
    "    for n in Ns:\n",
    "\n",
    "        #create pipeline with scaler and classifier\n",
    "        RF = RandomForestClassifier(n_estimators=n, criterion=\"entropy\", random_state=123)\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', RF)])\n",
    "\n",
    "        # perform cv using F1_score weighted\n",
    "        scores = cross_val_score(pipeline, X_train, y, cv = 5, scoring='f1_weighted')\n",
    "        mean_acc.append(np.mean(scores))\n",
    "    mean_acc_estimators_RF.append(mean_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(len(mean_acc_estimators_RF)):\n",
    "    plt.plot(Ns, mean_acc_estimators_RF[i], label=classes[i])    \n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('number of estimators (N)')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print( \"The best accuracy was with: \"+str(classes[i]), max(mean_acc_estimators_RF[i]), \"with N=\", Ns[np.argmax(mean_acc_estimators_RF[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_RF = list()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    best_RF = RandomForestClassifier(criterion=\"entropy\", random_state=123, max_depth=Ns[np.argmax(mean_acc_estimators_RF[i])])\n",
    "    y = y_train.iloc[:,i].values\n",
    "    best_RF.fit(X_scaled,y)\n",
    "    estimators_RF.append(best_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = list()\n",
    "\n",
    "for i in range(n_classes):\n",
    "\n",
    "    test_pred_m  = estimators_RF[i].predict(test_X_scaled)\n",
    "    print('Test Accuracy: '+str(classes[i])+' -- ', accuracy_score(y_test.iloc[:,i], test_pred_m))\n",
    "    test_pred.append(test_pred_m.reshape(-1,1))\n",
    "    \n",
    "\n",
    "    # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "    print('Test F1_score: '+str(classes[i])+' -- ', f1_score(y_test.iloc[:,i], test_pred_m, average='weighted'))\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred[0])\n",
    "len(test_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predf = np.concatenate(tuple(test_pred), axis=1)\n",
    "print(test_predf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy: ', accuracy_score(y_test, test_predf))\n",
    "    \n",
    "# print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "print('Test F1_score: ', f1_score(y_test, test_predf, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
