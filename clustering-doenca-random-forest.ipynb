{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "config_dirs = open(\"prefixo_dados.txt\").readlines() \n",
    "DIR_PREFIXO = Path(config_dirs[0].strip())\n",
    "\n",
    "\n",
    "DIRETORIO_PRINCIPAL =  DIR_PREFIXO / \"Projeto_PA\" / \"Projeto_PA_validado\"\n",
    "DIRETORIO_DATASET = DIR_PREFIXO / \"Projeto_PA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datset com todos os campos: metadados, medidas e estat√≠sticas\n",
    "df = pd.read_csv(DIRETORIO_PRINCIPAL / \"padrao_doenca\" / \"classificados_por_padroes_de_doenca_estatistica.csv\", sep=\";\")\n",
    "\n",
    "#display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all averages, standard deviations, and classes (types of diseases)\n",
    "df_medidas_doencas = df.iloc[:,1:172]\n",
    "#display(HTML(df_medidas_doencas.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medidas_doencas_sem_nan = df_medidas_doencas.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data_nascimento', 'genero', 'idade', 'peso', 'altura', 'data_exame',\n",
      "       'sist 9:00', 'sist 9:15', 'sist 9:30', 'sist 9:45',\n",
      "       ...\n",
      "       'diast 6:45', 'diast 7:00', 'diast 7:15', 'diast 7:30', 'diast 7:45',\n",
      "       'diast 8:00', 'diast 8:15', 'diast 8:30', 'diast 8:45', 'whitecoat'],\n",
      "      dtype='object', length=171)\n"
     ]
    }
   ],
   "source": [
    "print(df_medidas_doencas_sem_nan.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Gender M and F to binary \n",
    "# cleanup_nums = {\"Morning Surge\": {\"NaN\": False}}\n",
    "\n",
    "# df_medidas_doencas_sem_nan.replace(cleanup_nums, inplace=True)\n",
    "#display(HTML(df_medidas_doencas_sem_nan.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '1923-10-05'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d0ddc8d60f12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_medidas_doencas_sem_nan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleanup_nums\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_medidas_doencas_sem_nan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_medidas_doencas_sem_nan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   5880\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5881\u001b[0m             new_data = self._data.astype(\n\u001b[1;32m-> 5882\u001b[1;33m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5883\u001b[0m             )\n\u001b[0;32m   5884\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m                     \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m                     \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m                     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[1;31m# TODO(extension)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marta\\anaconda3\\envs\\emoti\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '1923-10-05'"
     ]
    }
   ],
   "source": [
    "# transform Gender M and F to binary \n",
    "cleanup_nums = {\"genero\": {\"M\": True, \"F\": False}}\n",
    "\n",
    "df_medidas_doencas_sem_nan.replace(cleanup_nums, inplace=True)\n",
    "df_medidas_doencas_sem_nan = df_medidas_doencas_sem_nan.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_medidas_doencas_sem_nan.iloc[:,:161]\n",
    "#display(HTML(df_X.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y = df_medidas_doencas_sem_nan.iloc[:,161:]\n",
    "#display(HTML(df_Y.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split between train and test with test_size of 0.3 (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape[0])\n",
    "display(X_train.head())\n",
    "\n",
    "print(X_test.shape[0])\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df_Y.values, axis=0).shape[0])\n",
    "display(np.unique(df_Y.values, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(np.argmax(df_Y.values, axis=1)))\n",
    "listm = np.unique(df_Y.values, axis=0).tolist()\n",
    "print(listm)\n",
    "print(listm[0])\n",
    "\n",
    "print([''.join(str(e) for e in i) for i in listm])\n",
    "\n",
    "print([int(''.join(str(e) for e in i),2) for i in listm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique([int(''.join(str(e) for e in i),2) for i in df_Y.values.tolist()], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "# from sklearn.tree import export_graphviz\n",
    "# from sklearn.externals.six import StringIO  \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Ms = np.arange(2,10)\n",
    "mean_acc = list()\n",
    "\n",
    "for k in Ms:\n",
    "    \n",
    "    #create classifier\n",
    "    drugTree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth=k)\n",
    "    \n",
    "    #create pipeline with scaler and classifier\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', drugTree)])\n",
    "    \n",
    "    # perform cv=10 with F1_scored weighted\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv = 5, scoring='f1_weighted')\n",
    "    mean_acc.append(np.mean(scores))\n",
    "\n",
    "# mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Ms,mean_acc,'g')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('max depth')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"The best accuracy was with\", max(mean_acc), \"with max_depth=\", Ms[np.argmax(mean_acc)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_drugTree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth = Ms[np.argmax(mean_acc)] )\n",
    "best_drugTree.fit(X_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTree = best_drugTree.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Accuracy: ', accuracy_score(y_train, predTree))\n",
    "print('Train F1_score: ', f1_score(y_train, predTree, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_scaled= scaler.transform(X_test)\n",
    "# test_X_scaled[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predTree  = best_drugTree.predict(test_X_scaled)\n",
    "#print(test_predTree)\n",
    "\n",
    "print('Test Accuracy: ', accuracy_score(y_test, test_predTree))\n",
    "\n",
    "# print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "print('Test F1_score: ', f1_score(y_test, test_predTree, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-output classifier - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth = Ms[np.argmax(mean_acc)] )\n",
    "#clf = MultiOutputClassifier(best_tree).fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predTree_m  = clf.predict(test_X_scaled)\n",
    "#print(test_predTree)\n",
    "\n",
    "# print('Test Accuracy: ', accuracy_score(y_test, test_predTree_m))\n",
    "\n",
    "# # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "# print('Test F1_score: ', f1_score(y_test, test_predTree_m, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-output classifier - RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ms = np.arange(2,20)\n",
    "# mean_acc = list()\n",
    "\n",
    "# for k in Ms:\n",
    "    \n",
    "#     #create classifier\n",
    "#     clf_forest = RandomForestClassifier(criterion=\"entropy\", random_state=123, max_depth=k)\n",
    "    \n",
    "#     #create pipeline with scaler and classifier\n",
    "#     pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', clf_forest)])\n",
    "    \n",
    "#     # perform cv=10 with F1_scored weighted\n",
    "#     scores = cross_val_score(pipeline, X_train, y_train, cv = 5, scoring='f1_weighted')\n",
    "#     mean_acc.append(np.mean(scores))\n",
    "\n",
    "# mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(Ms,mean_acc,'g')\n",
    "# plt.ylabel('F1 score')\n",
    "# plt.xlabel('Max leaf nodes')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"The best accuracy was with\", max(mean_acc), \"with max_depth=\", Ms[np.argmax(mean_acc)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_forest = RandomForestClassifier(criterion=\"entropy\", random_state=123, max_depth = Ms[np.argmax(mean_acc)] )\n",
    "# best_forest.fit(X_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_m  = best_forest.predict(test_X_scaled)\n",
    "# print(test_predTree)\n",
    "\n",
    "# print('Test Accuracy: ', accuracy_score(y_test, test_pred_m))\n",
    "\n",
    "# # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "# print('Test F1_score: ', f1_score(y_test, test_pred_m, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier per each class - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = y_train.shape[1]\n",
    "classes = y_train.columns.values.tolist()\n",
    "print(classes)\n",
    "print(n_classes)\n",
    "print(y_train.iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print('disease:'+str(classes[i]))\n",
    "    y = y_train.iloc[:,i].values\n",
    "    print('ones: ',(y == 1).sum())\n",
    "    print('zeros:',(y == 0).sum())\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print('disease:'+str(classes[i]))\n",
    "    y = y_test.iloc[:,i].values\n",
    "    print('ones: ',(y == 1).sum())\n",
    "    print('zeros:',(y == 0).sum())\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_estimators = list()\n",
    "Ms = np.arange(2,100)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_acc = list()\n",
    "    y = y_train.iloc[:,i].values\n",
    "    for k in Ms:\n",
    "\n",
    "        #create classifier\n",
    "        tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth=k)\n",
    "\n",
    "        #create pipeline with scaler and classifier\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', tree)])\n",
    "\n",
    "        # perform cv=10 with F1_scored weighted\n",
    "        scores = cross_val_score(pipeline, X_train, y, cv = 5, scoring='f1_weighted')\n",
    "        mean_acc.append(np.mean(scores))\n",
    "    mean_acc_estimators.append(mean_acc)\n",
    "# mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(len(mean_acc_estimators)):\n",
    "    plt.plot(Ms, mean_acc_estimators[i], label=classes[i])   \n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Max depth')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print( \"The best accuracy was with: \"+str(i), max(mean_acc_estimators[i]), \"with max_depth=\", Ms[np.argmax(mean_acc_estimators[i])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = list()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    best_Tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=123, max_depth = Ms[np.argmax(mean_acc_estimators[i])] )\n",
    "    y = y_train.iloc[:,i].values\n",
    "    best_Tree.fit(X_scaled,y)\n",
    "    estimators.append(best_Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "\n",
    "    test_pred_m  = estimators[i].predict(test_X_scaled)\n",
    "    print('Test Accuracy: '+str(classes[i])+' -- ', accuracy_score(y_test.iloc[:,i], test_pred_m))\n",
    "\n",
    "    # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "    print('Test F1_score: '+str(classes[i])+' -- ', f1_score(y_test.iloc[:,i], test_pred_m, average='weighted'))\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier per each class - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_estimators_LR = list()\n",
    "Cks = np.linspace(1e-3,100, 50)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_acc = list()\n",
    "    y = y_train.iloc[:,i].values\n",
    "\n",
    "    for Ck in Cks:\n",
    "\n",
    "        #create pipeline with scaler and classifier\n",
    "        LR = LogisticRegression(C=Ck, solver='liblinear')\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', LR)])\n",
    "\n",
    "        # perform cv using F1_score weighted\n",
    "        scores = cross_val_score(pipeline, X_train, y, cv = 5, scoring='f1_weighted')\n",
    "        mean_acc.append(np.mean(scores))\n",
    "    mean_acc_estimators_LR.append(mean_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mean_acc_estimators_LR))\n",
    "print(Cks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(len(mean_acc_estimators_LR)):\n",
    "    plt.plot(Cks, mean_acc_estimators_LR[i], label=classes[i])    \n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Regularization parameter (C)')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print( \"The best accuracy was with: \"+str(classes[i]), max(mean_acc_estimators_LR[i]), \"with C=\", Cks[np.argmax(mean_acc_estimators_LR[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators_LR = list()\n",
    "\n",
    "# for i in range(n_classes):\n",
    "#     best_LR = LogisticRegression(C=Cks[np.argmax(mean_acc_estimators_LR[i])], solver='liblinear')\n",
    "#     y = y_train.iloc[:,i].values\n",
    "#     best_LR.fit(X_scaled,y)\n",
    "#     estimators_LR.append(best_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(n_classes):\n",
    "\n",
    "#     test_pred_m  = estimators_LR[i].predict(test_X_scaled)\n",
    "#     print('Test Accuracy: '+str(classes[i])+' -- ', accuracy_score(y_test.iloc[:,i], test_pred_m))\n",
    "\n",
    "#     # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "#     print('Test F1_score: '+str(classes[i])+' -- ', f1_score(y_test.iloc[:,i], test_pred_m, average='weighted'))\n",
    "#     print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier per each class - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_estimators_RF = list()\n",
    "Ns = np.arange(2,50)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_acc = list()\n",
    "    y = y_train.iloc[:,i].values\n",
    "\n",
    "    for n in Ns:\n",
    "\n",
    "        #create pipeline with scaler and classifier\n",
    "        RF = RandomForestClassifier(n_estimators=n, criterion=\"entropy\", random_state=123)\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), ('estimator', RF)])\n",
    "\n",
    "        # perform cv using F1_score weighted\n",
    "        scores = cross_val_score(pipeline, X_train, y, cv = 5, scoring='f1_weighted')\n",
    "        mean_acc.append(np.mean(scores))\n",
    "    mean_acc_estimators_RF.append(mean_acc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(len(mean_acc_estimators_RF)):\n",
    "    plt.plot(Ns, mean_acc_estimators_RF[i], label=classes[i])    \n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('number of estimators (N)')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print( \"The best accuracy was with: \"+str(classes[i]), max(mean_acc_estimators_RF[i]), \"with N=\", Ns[np.argmax(mean_acc_estimators_RF[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_RF = list()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    best_RF = RandomForestClassifier(criterion=\"entropy\", random_state=123, max_depth=Ns[np.argmax(mean_acc_estimators_RF[i])])\n",
    "    y = y_train.iloc[:,i].values\n",
    "    best_RF.fit(X_scaled,y)\n",
    "    estimators_RF.append(best_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = list()\n",
    "\n",
    "for i in range(n_classes):\n",
    "\n",
    "    test_pred_m  = estimators_RF[i].predict(test_X_scaled)\n",
    "    print('Test Accuracy: '+str(classes[i])+' -- ', accuracy_score(y_test.iloc[:,i], test_pred_m))\n",
    "    test_pred.append(test_pred_m.reshape(-1,1))\n",
    "    \n",
    "\n",
    "    # print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "    print('Test F1_score: '+str(classes[i])+' -- ', f1_score(y_test.iloc[:,i], test_pred_m, average='weighted'))\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred[0])\n",
    "len(test_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predf = np.concatenate(tuple(test_pred), axis=1)\n",
    "print(test_predf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy: ', accuracy_score(y_test, test_predf))\n",
    "    \n",
    "# print('Test jaccard similarity score: ', jaccard_similarity_score(y_test, test_predTree))\n",
    "print('Test F1_score: ', f1_score(y_test, test_predf, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
